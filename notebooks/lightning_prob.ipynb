{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71dce86-478f-4a75-9a33-e3c825f92d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import folium\n",
    "import geopandas\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xarray\n",
    "from matplotlib.colors import ListedColormap\n",
    "from metpy.units import units\n",
    "from shapely.geometry import Polygon\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ahijevyc import G211\n",
    "from ahijevyc.lightning import get_obsgdf, ztfs\n",
    "from ahijevyc.spc import convective_outlook_colors, enhtstm_colors, get_issuance_time, get_outlooks\n",
    "from ml_functions import get_args, get_savedmodel_path, load_df, load_model, predct2\n",
    "from statisticplot import ax_features, make_map, pod, stat_plots\n",
    "\n",
    "sns.set_theme()\n",
    "logging.basicConfig(level=logging.WARNING, format=\"%(asctime)s %(message)s\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f9086-cd01-4ae1-8412-91ec490eebbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dpi = 200\n",
    "# color map for SPC outlook\n",
    "convective_outlook_colors\n",
    "# color map for SPC enhanced tstm outlook\n",
    "enhtstm_cmap = ListedColormap(list(enhtstm_colors.values()), name=\"tstm outlook\")\n",
    "enhtstm_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb288733-67c7-41a2-8a91-55959dbaa195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# map projection\n",
    "map_crs = G211.G211\n",
    "g211 = G211.GridManager()\n",
    "grid = g211.grid\n",
    "conus_mask = g211.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c39a4-e634-45c8-b286-44ddcb3e2ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shp2ds(gs, issue, valid_start_hour, valid_end_hour):\n",
    "    \"\"\"\n",
    "    convert geopandas dataframe to xarray dataset\n",
    "    \"\"\"\n",
    "    df = conus_mask.to_dataframe(name=\"conus\").join(gs.drop(columns=\"geometry\").sort_index())\n",
    "    da = []\n",
    "    for c in df.columns:\n",
    "        da.append(xarray.DataArray(df[c].unstack(\"x\").values, name=c, dims=[\"y\", \"x\"]))\n",
    "    ds = xarray.merge(da)\n",
    "    ds[\"issue\"] = issue\n",
    "    ds[\"valid_start_hour\"] = valid_start_hour\n",
    "    ds[\"valid_end_hour\"] = valid_end_hour\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7465c7f7-112d-4b8c-9688-a0e9694f889b",
   "metadata": {},
   "source": [
    "### Load SPC enhanced tstm outlook"
   ]
  },
  {
   "cell_type": "raw",
   "id": "639f3639-7d65-418e-820d-2c93ab106385",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "(glmval) crhtc85:/glade/derecho/scratch/ahijevyc/tmp/enhtstm> parallel --citation\n",
    "Academic tradition requires you to cite works you base your article on.\n",
    "If you use programs that use GNU Parallel to process data for an article in a\n",
    "scientific publication, please cite:\n",
    "\n",
    "@software{tange_2024_13357237,\n",
    "      author       = {Tange, Ole},\n",
    "      title        = {GNU Parallel 20240822 ('Southport')},\n",
    "      month        = Aug,\n",
    "      year         = 2023,\n",
    "      note         = {{GNU Parallel is a general parallelizer to run\n",
    "                       multiple serial command line programs in parallel\n",
    "                       without changing them.}},\n",
    "      publisher    = {Zenodo},\n",
    "      doi          = {10.5281/zenodo.13357237},\n",
    "      url          = {https://doi.org/10.5281/zenodo.13357237}\n",
    "}\n",
    "\n",
    "(Feel free to use \\nocite{tange_2024_13357237})\n",
    "\n",
    "This helps funding further development; AND IT WON'T COST YOU A CENT.\n",
    "If you pay 10000 EUR you should feel free to use GNU Parallel without citing.\n",
    "\n",
    "More about funding GNU Parallel and the citation notice:\n",
    "https://lists.gnu.org/archive/html/parallel/2013-11/msg00006.html\n",
    "https://www.gnu.org/software/parallel/parallel_design.html#citation-notice\n",
    "https://git.savannah.gnu.org/cgit/parallel.git/tree/doc/citation-notice-faq.txt\n",
    "\n",
    "\n",
    "Type: 'will cite' and press enter.\n",
    "> will cite\n",
    "\n",
    "Thank you for your support: You are the reason why there is funding to\n",
    "continue maintaining GNU Parallel. On behalf of future versions of\n",
    "GNU Parallel, which would not exist without your support:\n",
    "\n",
    "  THANK YOU SO MUCH\n",
    "\n",
    "It is really appreciated. The citation notice is now silenced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d747765-6496-4a4d-8fc7-bb95f2d24fbe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# downloaded by get_enhtstm.ipynb\n",
    "tmpdir = Path(os.getenv(\"TMPDIR\"))\n",
    "sfiles = (tmpdir / \"enhtstm\").glob(\"????/*.zip\")\n",
    "sfiles = sorted(sfiles)\n",
    "bad_file = tmpdir / \"enhtstm/2020/enh12_20200215_150400_202002150222-shp.zip\"  # incomplete\n",
    "assert bad_file not in sfiles\n",
    "\n",
    "encoding_dict = {\n",
    "    'index_poly': {'dtype': 'f4'},\n",
    "    'DN': {'dtype': 'f4'},\n",
    "}\n",
    "for ifile in tqdm(sfiles):\n",
    "    ofile = ifile.with_suffix(\".nc\")\n",
    "    if os.path.exists(ofile):\n",
    "        continue\n",
    "    gs = geopandas.read_file(ifile)\n",
    "\n",
    "    issue, valid_start, valid_end = get_issuance_time(ifile)\n",
    "\n",
    "    gs = grid.to_crs(gs.crs).sjoin(gs, how=\"inner\", rsuffix=\"poly\")\n",
    "    # convert shapes to grid\n",
    "    ds = shp2ds(gs, issue, valid_start.hour, valid_end.hour)\n",
    "    #print(ofile)\n",
    "    ds.to_netcdf(ofile, encoding=encoding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7139b641-a2b1-49ee-997e-71001a43b06b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SPC convective outlooks\n",
    "convoutlook = False\n",
    "if convoutlook:\n",
    "    agdf = get_outlooks()\n",
    "    agdf.head(170).tail()\n",
    "\n",
    "    # examples of SPC issuances with a particular risk threshold\n",
    "    risk = \"ENH\"\n",
    "    ih = agdf[\"THRESHOLD\"] == risk\n",
    "    print(f\"{sum(ih)} {risk} risk days\")\n",
    "    c = agdf.loc[ih].sort_values(\"PRODISS\").PRODISS.values\n",
    "    print(c[20::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf3edee-b8f8-4baa-8a08-f5cbe50a0948",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tmpdir.glob(\"enhtstm/2021/enh00_20210722_222000_2021072*-shp.zip\")\n",
    "list(m)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8837dcde-a6f1-4ae7-9629-3e018da56794",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ifile = sfiles[5098]\n",
    "# ifile = sfiles[4853]\n",
    "# ifile = tmpdir / \"enhtstm/2021/enh20_20210721_211600_202107210450-shp.zip\"\n",
    "ifile = tmpdir / \"enhtstm/2021/enh00_20210819_192000_202108190503-shp.zip\"\n",
    "gs = geopandas.read_file(ifile)\n",
    "gs = gs.rename(columns={\"DN\": \"SPC\"})\n",
    "issue, valid_start, valid_end = get_issuance_time(ifile)\n",
    "\n",
    "\n",
    "# Experimental: instead of setting NaNs to zero after sjoin and converting to int,\n",
    "# avoid NaNs by adding a \"zeros\" GeoDataFrame with SPC = 0 for all area\n",
    "# outside enhanced tstm polygons. Is it cleaner? Perhaps not.\n",
    "# Define global geometry\n",
    "global_geom = Polygon([(-180, -90), (-180, 89), (180, 89), (180, -90)])\n",
    "# Set SPC = 0 in global geometry.\n",
    "zeros = geopandas.GeoDataFrame(\n",
    "    {\"SPC\": [0], \"geometry\": global_geom},\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "# subtract gs area\n",
    "zeros = zeros.overlay(gs.to_crs(\"EPSG:4326\"), how=\"difference\")\n",
    "# Combine zeros area with gs.\n",
    "gs = pd.concat([gs.to_crs(zeros.crs), zeros]).reset_index(drop=True)\n",
    "# Assign value to grid points within polygons\n",
    "gs = grid[conus_mask.values.ravel()].to_crs(gs.crs).sjoin(gs, how=\"left\", rsuffix=\"poly\")\n",
    "gs[\"issue\"] = issue\n",
    "# convert to str avoids TypeError: Object of type Timestamp is not JSON serializable\n",
    "gs[\"valid_start\"] = valid_start.strftime(\"%Y%m%d %H:%M\")\n",
    "gs[\"valid_end\"] = valid_end.strftime(\"%Y%m%d %H:%M\")\n",
    "issue, valid_start, valid_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb3f55e-42e9-4725-b93c-881a441e57ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if convoutlook:\n",
    "    import requests\n",
    "\n",
    "    # Choose a particular convective outlook, grab issue time and expire time\n",
    "    prodiss = \"201803261955\"\n",
    "    issue = pd.to_datetime(agdf[agdf.PRODISS.eq(prodiss)].ISSUE.iloc[0])\n",
    "    expire = pd.to_datetime(agdf[agdf.PRODISS.eq(prodiss)].EXPIRE.iloc[0])\n",
    "\n",
    "    if issue < pd.to_datetime(\"20221128\"):\n",
    "        column = \"THRESHOLD\"\n",
    "        subset = agdf[\"DAY\"].eq(1) & agdf[\"CATEGORY\"].eq(\"CATEGORICAL\")\n",
    "        subset = subset & agdf[\"PRODISS\"].eq(prodiss)\n",
    "        gdf = agdf[subset]\n",
    "    else:\n",
    "        ifile = requests.get(\"https://www.spc.noaa.gov/products/outlook/day1otlk_cat.nolyr.geojson\")\n",
    "        gdf = geopandas.GeoDataFrame.from_features(ifile.json())\n",
    "        gdf = gdf.set_crs(\"epsg:4269\")\n",
    "        column = \"LABEL\"\n",
    "    gdf\n",
    "\n",
    "    if False:\n",
    "        # Subtract higher thresholds from lower thresholds so they don't overlap\n",
    "        cat = \"TSTM\"\n",
    "        for subtract in [\"MRGL\", \"SLGT\", \"ENH\", \"MDT\", \"HIGH\"]:\n",
    "            logging.debug(f\"subtracting {subtract}\")\n",
    "            gdf.loc[gdf[column].eq(cat)] = (\n",
    "                gdf.loc[gdf[column].eq(cat)]\n",
    "                .overlay(gdf[gdf[column].eq(subtract)], how=\"difference\")\n",
    "                .values\n",
    "            )\n",
    "            cat = subtract\n",
    "            if subtract not in gdf[column]:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46716262-d4a3-48e2-a102-0e6389277a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spc_fcst = gs.to_crs(ccrs.PlateCarree())\n",
    "column = \"SPC\"\n",
    "obsvar = \"cg\"\n",
    "o_thresh = 1\n",
    "twin = 4\n",
    "rptdist = 20\n",
    "\n",
    "\n",
    "args = get_args(o_thresh, twin)\n",
    "\n",
    "setattr(args, \"idate\", pd.to_datetime(valid_start).floor(\"1D\"))\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa58389-2283-42af-9079-052f21fa6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsgdf = get_obsgdf(args, valid_start, obsvar, rptdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f957465f-fd12-4066-9b72-e11bc7922f27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import folium.plugins\n",
    "\n",
    "m = folium.plugins.DualMap(location=[40, -95], zoom_start=3)\n",
    "# 40-km rptdist\n",
    "get_obsgdf(args, valid_start, obsvar, 40).explore(\n",
    "    m=m.m1,\n",
    "    column=obsvar,\n",
    "    name=\"40\",\n",
    "    cmap=\"pink_r\",\n",
    ")\n",
    "# 20-km rptdist\n",
    "obsgdf.explore(\n",
    "    m=m.m2,\n",
    "    column=obsvar,\n",
    "    cmap=\"pink_r\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de1b52e-3339-44bb-8fe8-ebb1908f3518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = (\n",
    "    geopandas.read_file(ifile)\n",
    "    .rename(columns={\"DN\": \"SPC\"})\n",
    "    .explore(\n",
    "        column=column,\n",
    "        categories=sorted(spc_fcst[column].unique().tolist()),\n",
    "        cmap=enhtstm_cmap,\n",
    "        name=\"SPC\",\n",
    "    )\n",
    ")\n",
    "spc_fcst.explore(\n",
    "    m=m,\n",
    "    column=column,\n",
    "    categories=sorted(spc_fcst[column].unique().tolist()),\n",
    "    cmap=enhtstm_cmap,\n",
    "    name=\"gridded SPC\",\n",
    "    marker_kwds=dict(radius=4),\n",
    ")\n",
    "obsgdf[obsgdf[obsvar] >= o_thresh].explore(\n",
    "    m=m, marker_kwds=dict(color=\"yellow\", fill=False), name=f\"{obsvar} â‰¥ {o_thresh}\"\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e2d241-58b4-4b67-afc3-c780e66f90bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MOS LAMP lightning forecast\n",
    "LAMP = False\n",
    "if LAMP:\n",
    "    from awips.dataaccess import DataAccessLayer\n",
    "\n",
    "    DataAccessLayer.changeEDEXHost(\"edex-cloud.unidata.ucar.edu\")\n",
    "    request = DataAccessLayer.newDataRequest()\n",
    "    request.setDatatype(\"grid\")\n",
    "    request.setLocationNames(\"LAMP2p5\")\n",
    "    request.setParameters(\"PROLGHT2hr\")\n",
    "    # request.setLevels(\"2.0FHAG\")\n",
    "\n",
    "    # Take a look at our request\n",
    "    logging.info(request)\n",
    "\n",
    "    grid_locations = DataAccessLayer.getAvailableLevels(request)\n",
    "    grid_locations.sort()\n",
    "    list(grid_locations)\n",
    "\n",
    "    cycles = DataAccessLayer.getAvailableTimes(request, True)\n",
    "    times = DataAccessLayer.getAvailableTimes(request)\n",
    "    fcstRun = DataAccessLayer.getForecastRun(cycles[-1], times)\n",
    "\n",
    "    # Get the most recent grid data\n",
    "    response = DataAccessLayer.getGridData(request, [fcstRun[0]])\n",
    "\n",
    "    logging.info(f\"{len(times)} available times {len(fcstRun)} forecast runs\")\n",
    "\n",
    "    grid = response[0]\n",
    "    data = grid.getRawData()\n",
    "    lons, lats = grid.getLatLonCoords()\n",
    "    bbox = [lons.min(), lons.max(), lats.min(), lats.max()]\n",
    "\n",
    "    data[data == -999999] = np.nan\n",
    "    data.min()\n",
    "    np.nanmin(data)\n",
    "\n",
    "    fig, ax = make_map(bbox=bbox, projection=map_crs)\n",
    "    cs = ax.pcolormesh(lons, lats, data, cmap=\"pink_r\", transform=ccrs.PlateCarree())\n",
    "    cbar = fig.colorbar(cs, shrink=0.7, orientation=\"horizontal\")\n",
    "    cbar.set_label(\n",
    "        grid.getLocationName()\n",
    "        + \" \"\n",
    "        + grid.getLevel()\n",
    "        + \" \"\n",
    "        + grid.getParameter()\n",
    "        + \" (\"\n",
    "        + grid.getUnit()\n",
    "        + \") \"\n",
    "        + \"valid \"\n",
    "        + str(grid.getDataTime().getRefTime())\n",
    "    )\n",
    "\n",
    "    fig2, ax2 = make_map(bbox=bbox, projection=map_crs)\n",
    "    cs2 = ax2.contour(\n",
    "        lons,\n",
    "        lats,\n",
    "        data,\n",
    "        80,\n",
    "        cmap=\"pink_r\",\n",
    "        levels=6,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        vmin=np.nanmin(data),\n",
    "        vmax=np.nanmax(data),\n",
    "    )\n",
    "    cbar2 = fig2.colorbar(cs2, shrink=0.7, orientation=\"horizontal\")\n",
    "    cbar2.set_label(\n",
    "        grid.getLocationName()\n",
    "        + \" \"\n",
    "        + grid.getLevel()\n",
    "        + \" \"\n",
    "        + grid.getParameter()\n",
    "        + \" (\"\n",
    "        + grid.getUnit()\n",
    "        + \") \"\n",
    "        + \"valid \"\n",
    "        + str(grid.getDataTime().getRefTime())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7de2e3-4c94-442e-8c40-fb5b7db7ade2",
   "metadata": {},
   "source": [
    "## Define observation numpy array, geodataframe, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d2a1c-5a2e-43a4-99f2-162c2e75bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple 1-D numpy array of observations for verification\n",
    "obs = obsgdf.set_index([\"x\", \"y\"])[obsvar]\n",
    "\n",
    "# drop nans outside CONUS (mask applied earlier)\n",
    "obs = obs[~np.isnan(obs)]\n",
    "\n",
    "# truncate observation geodataframe based on event threshold (used for plots)\n",
    "o = obsgdf[obsgdf[obsvar] >= o_thresh]\n",
    "\n",
    "# Alternative event thresholds for observations (evenly spaced logrithmically)\n",
    "thresh = np.round(np.logspace(0, 3, 16), decimals=0).astype(int)\n",
    "thresh = pd.Series([o_thresh], name=f\"{obsvar} threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea63997-8686-4044-91a2-697e1061f8f1",
   "metadata": {},
   "source": [
    "### Verify SPC enhanced tstm forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae637427-d31d-4575-bb3a-8fd576176d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = spc_fcst\n",
    "# so we can apply 6045-element mask\n",
    "fcst = fcst.merge(grid, on=[\"x\", \"y\"], how=\"right\")\n",
    "fcst = fcst.SPC / 100\n",
    "# Drop values outside CONUS\n",
    "fcst = fcst[conus_mask.data.ravel()]\n",
    "# Assign 0 to points outside forecast polygons\n",
    "fcst[np.isnan(fcst)] = 0\n",
    "fcst.name = \"SPC\"\n",
    "\n",
    "pthresh = pd.Series([10, 40, 70], name=f\"fcst prob\\nthresh\") / 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7878bd46-ce81-48ee-b0ca-d6416e10d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0907c0ba-826f-4390-82e2-e941f8b37283",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_defaults()\n",
    "fig, ax = make_map()\n",
    "ax.set_title(f\"{issue} outlook valid {valid_start} - {valid_end}\")\n",
    "gs = geopandas.read_file(ifile).to_crs(ax.projection)\n",
    "gs[\"DN\"] /= 100.0\n",
    "gs.plot(\n",
    "    ax=ax,\n",
    "    column=\"DN\",\n",
    "    cmap=enhtstm_cmap,\n",
    "    alpha=0.5,\n",
    "    legend=True,\n",
    "    norm=mpl.colors.BoundaryNorm(boundaries=[0, 0.10, 0.40, 0.70, 1], ncolors=4),\n",
    "    legend_kwds=dict(\n",
    "        shrink=0.7,\n",
    "        orientation=\"horizontal\",\n",
    "        aspect=25,\n",
    "        pad=0.05,\n",
    "        label=f\"prob of Tstm within 12 mi ({(12*units.miles).to('km'):~.1f})\",\n",
    "        spacing=\"proportional\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "gs = spc_fcst.copy()\n",
    "gs[\"SPC\"] /= 100.0\n",
    "gs.where(gs.SPC > 0).plot(\n",
    "    column=\"SPC\",\n",
    "    ax=ax,\n",
    "    cmap=enhtstm_cmap,\n",
    "    norm=mpl.colors.BoundaryNorm(boundaries=[0, 0.10, 0.40, 0.70, 1], ncolors=4),\n",
    "    marker=\"o\",\n",
    "    markersize=20,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    label=\"gridded SPC\",\n",
    ")\n",
    "\n",
    "o_kw = {\n",
    "    \"marker\": \"o\",\n",
    "    \"markersize\": 18,\n",
    "    \"edgecolor\": \"black\",\n",
    "    \"facecolor\": \"yellow\",\n",
    "    \"label\": f\"{o_thresh}+{obsvar}\",\n",
    "    \"linewidths\": 0.3,\n",
    "}\n",
    "o.plot(\n",
    "    ax=ax,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    **o_kw,\n",
    ")\n",
    "\n",
    "leg = ax.legend()\n",
    "plt.tight_layout()\n",
    "ofile = tmpdir / \"spc.png\"\n",
    "fig.savefig(ofile, dpi=dpi)\n",
    "print(ofile)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72835d09-1f1c-47ac-b76c-60f98da585b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0 = stat_plots(\n",
    "    obs,\n",
    "    fcst,\n",
    "    thresh=thresh,\n",
    "    pthresh=pthresh,\n",
    "    o_thresh_roc=o_thresh,\n",
    "    sep=0.01,\n",
    "    n_bins=11,\n",
    "    suptitle=f\"{issue} outlook valid {valid_start} - {valid_end} vs {o_thresh}+{obsvar}\",\n",
    ")\n",
    "ofile = tmpdir / \"t.png\"\n",
    "fig0.savefig(ofile, dpi=dpi)\n",
    "logging.warning(ofile)\n",
    "fig0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ce10e4-1ded-4e14-bb44-5d8c75d1e565",
   "metadata": {},
   "source": [
    "## Verify dense neural network forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd534c-1bf4-4205-b945-5967e88c08b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "setattr(args, \"idate\", pd.to_datetime(\"20210713\"))\n",
    "df = load_df(args)\n",
    "\n",
    "# Put \"valid_time\", \"y\", and \"x\" in MultiIndex so we can group by them later.\n",
    "# Used here and when calculating ensemble mean.\n",
    "levels = [\"initialization_time\", \"valid_time\", \"y\", \"x\"]\n",
    "df = df.set_index(levels)\n",
    "feature_levels = [\"forecast_hour\", \"lat\", \"lon\"]\n",
    "df = df.set_index(feature_levels, drop=False, append=True)\n",
    "levels = levels + feature_levels\n",
    "\n",
    "# make sure df label is same as obs (got earlier)\n",
    "assert all(\n",
    "    df[f\"{obsvar}_{rptdist}km_{twin}hr\"].xs(\n",
    "        valid_start + pd.Timedelta(hours=twin / 2), level=\"valid_time\"\n",
    "    )\n",
    "    == obs.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489dc9a-561e-4732-8c96-f0880946d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0a46f-5414-4061-9f9f-e554df7fbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedmodel = get_savedmodel_path(args, odir=\"/glade/work/ahijevyc/NSC_objects/nn\")\n",
    "logging.warning(savedmodel)\n",
    "ifold, thisfit = 0, 0\n",
    "savedmodel_thisfitfold = f\"{savedmodel}_{thisfit}/{args.kfold}fold{ifold}\"\n",
    "model = load_model(savedmodel_thisfitfold)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e4eecf-5128-4607-88bb-f5471b350538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_product([range(args.kfold), range(args.nfits)], names=[\"fold\", \"fit\"])\n",
    "\n",
    "Y = pd.concat([predct2(i, args, df) for i in index], keys=index, names=index.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2e4731-966f-43d2-9b7b-9a333cb89b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I may have overlapping valid_times from different init_times like fhr=1 from today and fhr=25 from previous day\n",
    "# average probability over all nfits initialized at initialization_time and valid at valid_time\n",
    "ensmean = Y.groupby(level=levels).mean()\n",
    "assert (\n",
    "    \"fit\" not in ensmean.index.names\n",
    "), \"fit should not be a MultiIndex level of ensmean, the average probability over nfits.\"\n",
    "\n",
    "dnntimes = pd.date_range(\n",
    "    start=valid_start + pd.Timedelta(hours=twin / 2),\n",
    "    end=valid_end - pd.Timedelta(hours=twin / 2),\n",
    "    freq=f\"{twin}h\",\n",
    ")\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "ensmean = ensmean.loc[idx[:, dnntimes], :].xs(\"y_pred\", axis=\"columns\", level=0)\n",
    "ensmean.groupby(\"valid_time\").first().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c0eb7-fd65-46c5-9f6f-789d069b0a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "o_kw.update({\"markersize\": 8})\n",
    "matplotlib.pyplot.close()\n",
    "sns.reset_defaults()\n",
    "f = f\"{obsvar}_{rptdist}km_{twin}hr\"\n",
    "labels = (\n",
    "    Y.groupby(level=levels).mean().loc[idx[:, dnntimes], :].xs(\"y_label\", axis=\"columns\", level=0)\n",
    ")\n",
    "\n",
    "assert np.all(labels[f].values == obs)\n",
    "\n",
    "\n",
    "def getp(ensmean):\n",
    "    # probability of no occurences during long time window = product of 1-p for all\n",
    "    # smaller time window pieces\n",
    "\n",
    "    prob_none = (1 - ensmean).groupby([\"y\", \"x\"]).prod()\n",
    "    # 1 minus prob_none = prob of at least one occurence.\n",
    "    p = 1 - prob_none\n",
    "    # add to df so we can use df's lat and lon for coordinates.\n",
    "    p[\"lon\"] = df.groupby([\"y\", \"x\"]).mean(numeric_only=True).lon\n",
    "    p[\"lat\"] = df.groupby([\"y\", \"x\"]).mean(numeric_only=True).lat\n",
    "    return p\n",
    "\n",
    "\n",
    "def put_colorbar(fig, ax):\n",
    "    cb = fig.colorbar(\n",
    "        ax.findobj(match=matplotlib.collections.PathCollection)[0],\n",
    "        ax=ax,\n",
    "        shrink=0.8,\n",
    "        orientation=\"horizontal\",\n",
    "        aspect=25,\n",
    "        pad=0.05,\n",
    "        spacing=\"proportional\",\n",
    "        label=f\"NNPF {o_thresh}+{f}\",\n",
    "    )\n",
    "    return cb\n",
    "\n",
    "\n",
    "p_kw = dict(\n",
    "    kind=\"scatter\",\n",
    "    x=\"lon\",\n",
    "    y=\"lat\",\n",
    "    s=12.1,\n",
    "    marker=\"s\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    colorbar=False,\n",
    "    # label=\"NNPF\",\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=2, figsize=(8, 3.55), subplot_kw={\"projection\": map_crs}, sharey=True\n",
    ")\n",
    "ax = axes[0]\n",
    "p = getp(ensmean)\n",
    "\n",
    "ax = p.plot(\n",
    "    ax=ax,\n",
    "    cmap=\"icefire\",\n",
    "    c=f,\n",
    "    vmax=1,\n",
    "    **p_kw,\n",
    ")\n",
    "cb = put_colorbar(fig, ax)\n",
    "\n",
    "ax = axes[1]\n",
    "# 0-10-40-70\n",
    "p = getp(ensmean.map(ztfs, how=\"floor\"))\n",
    "ax = p.plot(\n",
    "    ax=ax,\n",
    "    cmap=enhtstm_cmap,\n",
    "    c=f,\n",
    "    norm=mpl.colors.BoundaryNorm(boundaries=[0.00, 0.10, 0.40, 0.70, 1.00], ncolors=4),\n",
    "    **p_kw,\n",
    ")\n",
    "cb = put_colorbar(fig, ax)\n",
    "fig.suptitle(f\"NNPF initialized {args.idate}  valid {valid_start} - {valid_end}\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax = ax_features(ax)\n",
    "    ax = o.plot(\n",
    "        ax=ax,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        **o_kw,\n",
    "    )\n",
    "    leg = ax.legend()\n",
    "\n",
    "axes[0].set_title(\"a)\", loc=\"left\")\n",
    "axes[1].set_title(\"b)\", loc=\"left\")\n",
    "\n",
    "ofile = tmpdir / \"ztfs.png\"\n",
    "plt.tight_layout()\n",
    "fig.savefig(ofile, dpi=dpi)\n",
    "logging.warning(ofile)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b122ea-4a70-4c1d-b82e-037b427a0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "p[f].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf6062-ad6a-4f48-b765-46e4f7aa242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = p[f]\n",
    "# pthresh = pd.Series(np.round(np.arange(0.2, 1, 0.2), 2), name=f\"fcst\\np thresh\")\n",
    "\n",
    "fig0 = stat_plots(\n",
    "    obs,\n",
    "    fcst,\n",
    "    thresh=thresh,\n",
    "    pthresh=pthresh,\n",
    "    o_thresh_roc=o_thresh,\n",
    "    sep=0.15,\n",
    "    n_bins=11,\n",
    "    suptitle=(\n",
    "        f\"{issue} outlook valid {valid_start} - {valid_end}\"\n",
    "        f\"\\nDNN initialized {args.idate} vs {o_thresh}+{obsvar}\"\n",
    "    ),\n",
    "    fig=fig0,\n",
    ")\n",
    "\n",
    "fig0.savefig(tmpdir / \"t.png\", dpi=dpi)\n",
    "fig0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198926d4-236d-4d0e-bb44-935f702c33f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1 >= (pd.Series([10, 40, 70], name=f\"fcst prob\\nthresh\") / 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f12ce3-8044-4b40-8318-ac4fa2831ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec081a39-114a-476b-9bf7-24743aba8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst >= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3526dc9-34a3-417d-9c53-cee4d372bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "[pod(obs >= thresh[0], fcst >= p) for p in pthresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030cd31e-eea8-446a-b96c-2e441bb940df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pthresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4ac2c-5c3a-434d-be35-5b67af24bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1410582a-3253-4e6d-9e0a-5b3efe8a1458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
